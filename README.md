对rosbag和cv_bridge了解之后，知道了这个项目的一部分重点在于如何用rosbag以及用cv_bridge对ros2和opencv进行连接，可能通过rosbag播放后获取的视频中的图像是ros2的图像，想要交给opencv处理就必须先通过cv_bridge将其变为cv中的图像mat类型数据。

图像识别可以找到教程和开源代码进行学习，目前需要先弄明白如何用rqt播放这个视频，再想办法应用起来图像识别的算法。

通过rqt可以监听到视频的bag的数据，这个bag的数据是以某个topic的形式发送出去的，所以应该三要通过一个subscriber来订阅这个topic，然后获取每帧的图像，然后将其通过cv_bridge转换成cv的mat类型，然后再用图像识别的算法， 然后将这一帧输出到一个新的视频文件中

中间出现了点意外，没法用CMakeLists来编译使用opencv和cv_bridge，一直没想明白怎么回事，找了ros的库也没发现opencv，各种查找如何用自己的opencv，但是还是没能行，后续寄希望于ros2版本，尝试安装galactic版本以为能解决问题，但是折腾后发现我的galactic版本不支持ubuntu22。

转变思路，既然编译ros2项目也主要是用了CMakeLists，那直接去找找在如何使用CMakeLists编译使用opencv就好了（搜索ros2编译使用opencv的结果找不到我想要的），然后就发现原来是自己的CMakeLists写的有问题
ament_target_dependencies(listener rclcpp std_msgs sensor_msgs cv_bridge OpenCV)，我想要在listener中使用，但是写到talker那里去了。

但是目前有一个问题，就是我还是没想到怎么订阅ros2 bag play播放的视频数据，网上找到的有一个案例，但是它是用的ros，里面的一些类型都不一样了。我想可以先使用工具将bag转换为视频数据，然后再用传统的opencv来读取和应用算法，后续再想办法怎么解决这个问题

噢原来可以通过ros2 bag info来查看这个包发送的数据是什么类型的，这就好办了，前面困扰我的就是不知道什么类型的数据，这下子知道了数据的类型不就好办了吗。

ok目前实现了从ros2 bag play解析图像的步骤了，接下来尝试将网上的目标识别算法应用上去之后再将每次处理后的结果输出成视频就行了

输出视频遇到一点点小问题，但是问题不大，基本上算是完成这个小项目了，下班！！！
